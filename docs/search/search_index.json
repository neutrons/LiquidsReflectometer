{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Liquids Reflectometer Reduction User Guide Conda Environments Releases Contacting the Team The best mechanism for a user to request a change or report a bug is to contact the SANS CIS. Please email Mathieu Doucet with your request. A change needs to be in the form of a: Story for any enhancement request Defect for any bug fix request. API lr_reduction Developer Guide Contributing Guide Developer Documentation","title":"Liquids Reflectometer Reduction"},{"location":"#liquids-reflectometer-reduction","text":"","title":"Liquids Reflectometer Reduction"},{"location":"#user-guide","text":"Conda Environments Releases","title":"User Guide"},{"location":"#contacting-the-team","text":"The best mechanism for a user to request a change or report a bug is to contact the SANS CIS. Please email Mathieu Doucet with your request. A change needs to be in the form of a: Story for any enhancement request Defect for any bug fix request.","title":"Contacting the Team"},{"location":"#api","text":"lr_reduction","title":"API"},{"location":"#developer-guide","text":"Contributing Guide Developer Documentation","title":"Developer Guide"},{"location":"releases/","text":"Release Notes Notes for major or minor releases. Notes for patch releases are deferred. Release notes are written in reverse chronological order, with the most recent release at the top, using the following format: ## <Next Major or Minor Release> (date of release, format YYYY-MM-DD) **Of interest to the User**: - PR #XYZ one-liner description **Of interest to the Developer:** - PR #XYZ one-liner description 2.1.0 Of interest to the User : PR #33 enable dead time correction for runs with skipped pulses PR #26 add dead time correction to the computation of scaling factors PR #23 add dead time correction PR #19 Functionality to use two backgrounds PR #15 Ability to fit a background with a polynomial function Of interest to the Developer: PR #40 documentation to create a patch release PR #37 documentation conforming to that of the python project template PR #36 versioning with versioningit PR #25 Read in error events when computing correction PR #21 switch dependency from mantidworkbench to mantid PR #20 allow runtime initialization of new attributes for ReductionParameters PR #14 add first GitHub actions PR #12 switch from mantid to mantidworkbench conda package","title":"Release Notes"},{"location":"releases/#release-notes","text":"Notes for major or minor releases. Notes for patch releases are deferred. Release notes are written in reverse chronological order, with the most recent release at the top, using the following format: ## <Next Major or Minor Release> (date of release, format YYYY-MM-DD) **Of interest to the User**: - PR #XYZ one-liner description **Of interest to the Developer:** - PR #XYZ one-liner description","title":"Release Notes"},{"location":"releases/#210","text":"Of interest to the User : PR #33 enable dead time correction for runs with skipped pulses PR #26 add dead time correction to the computation of scaling factors PR #23 add dead time correction PR #19 Functionality to use two backgrounds PR #15 Ability to fit a background with a polynomial function Of interest to the Developer: PR #40 documentation to create a patch release PR #37 documentation conforming to that of the python project template PR #36 versioning with versioningit PR #25 Read in error events when computing correction PR #21 switch dependency from mantidworkbench to mantid PR #20 allow runtime initialization of new attributes for ReductionParameters PR #14 add first GitHub actions PR #12 switch from mantid to mantidworkbench conda package","title":"2.1.0"},{"location":"api/","text":"Overview lr_reduction.background lr_reduction.event_reduction lr_reduction.output lr_reduction.peak_finding lr_reduction.reduction_template_reader lr_reduction.template lr_reduction.time_resolved lr_reduction.utils lr_reduction.workflow","title":"Overview"},{"location":"api/#overview","text":"lr_reduction.background lr_reduction.event_reduction lr_reduction.output lr_reduction.peak_finding lr_reduction.reduction_template_reader lr_reduction.template lr_reduction.time_resolved lr_reduction.utils lr_reduction.workflow","title":"Overview"},{"location":"api/background/","text":"find_ranges_without_overlap Returns the part of r1 that does not contain r2 When summing pixels for reflectivity, include the full range, which means that for a range [a, b], b is included. The range that we return must always exclude the pixels included in r2. Parameters r1 : list Range of pixels to consider r2 : list Range of pixels to exclude Returns list List of ranges that do not overlap with r2 functional_background Estimate background using a linear function over a background range that may include the specular peak. In the case where the peak is included in the background range, the peak is excluded from the background. Parameters ws : Mantid workspace Workspace containing the data event_reflectivity : EventReflectivity EventReflectivity object peak : list Range of pixels that define the peak bck : list Range of pixels that define the background. It contains 4 pixels, defining up to two ranges. low_res : list Range in the x direction on the detector normalize_to_single_pixel : bool If True, the background is normalized to the number of pixels used to integrate the signal q_bins : numpy.ndarray Array of Q bins wl_dist : numpy.ndarray Wavelength distribution for the case where we use weighted events for normatization wl_bins : numpy.ndarray Array of wavelength bins for the case where we use weighted events for normatization q_summing : bool If True, sum the counts in Q bins Returns numpy.ndarray Reflectivity background numpy.ndarray Reflectivity background error side_background Original background substration done using two pixels defining the area next to the specular peak that are considered background. Parameters ws : Mantid workspace Workspace containing the data event_reflectivity : EventReflectivity EventReflectivity object peak : list Range of pixels that define the peak bck : list Range of pixels that define the background low_res : list Range in the x direction on the detector normalize_to_single_pixel : bool If True, the background is normalized to the number of pixels used to integrate the signal q_bins : numpy.ndarray Array of Q bins wl_dist : numpy.ndarray Wavelength distribution for the case where we use weighted events for normatization wl_bins : numpy.ndarray Array of wavelength bins for the case where we use weighted events for normatization q_summing : bool If True, sum the counts in Q bins Returns numpy.ndarray Reflectivity background numpy.ndarray Reflectivity background error","title":"Background"},{"location":"api/background/#lr_reduction.background.find_ranges_without_overlap","text":"Returns the part of r1 that does not contain r2 When summing pixels for reflectivity, include the full range, which means that for a range [a, b], b is included. The range that we return must always exclude the pixels included in r2.","title":"find_ranges_without_overlap"},{"location":"api/background/#lr_reduction.background.find_ranges_without_overlap--parameters","text":"r1 : list Range of pixels to consider r2 : list Range of pixels to exclude","title":"Parameters"},{"location":"api/background/#lr_reduction.background.find_ranges_without_overlap--returns","text":"list List of ranges that do not overlap with r2","title":"Returns"},{"location":"api/background/#lr_reduction.background.functional_background","text":"Estimate background using a linear function over a background range that may include the specular peak. In the case where the peak is included in the background range, the peak is excluded from the background.","title":"functional_background"},{"location":"api/background/#lr_reduction.background.functional_background--parameters","text":"ws : Mantid workspace Workspace containing the data event_reflectivity : EventReflectivity EventReflectivity object peak : list Range of pixels that define the peak bck : list Range of pixels that define the background. It contains 4 pixels, defining up to two ranges. low_res : list Range in the x direction on the detector normalize_to_single_pixel : bool If True, the background is normalized to the number of pixels used to integrate the signal q_bins : numpy.ndarray Array of Q bins wl_dist : numpy.ndarray Wavelength distribution for the case where we use weighted events for normatization wl_bins : numpy.ndarray Array of wavelength bins for the case where we use weighted events for normatization q_summing : bool If True, sum the counts in Q bins","title":"Parameters"},{"location":"api/background/#lr_reduction.background.functional_background--returns","text":"numpy.ndarray Reflectivity background numpy.ndarray Reflectivity background error","title":"Returns"},{"location":"api/background/#lr_reduction.background.side_background","text":"Original background substration done using two pixels defining the area next to the specular peak that are considered background.","title":"side_background"},{"location":"api/background/#lr_reduction.background.side_background--parameters","text":"ws : Mantid workspace Workspace containing the data event_reflectivity : EventReflectivity EventReflectivity object peak : list Range of pixels that define the peak bck : list Range of pixels that define the background low_res : list Range in the x direction on the detector normalize_to_single_pixel : bool If True, the background is normalized to the number of pixels used to integrate the signal q_bins : numpy.ndarray Array of Q bins wl_dist : numpy.ndarray Wavelength distribution for the case where we use weighted events for normatization wl_bins : numpy.ndarray Array of wavelength bins for the case where we use weighted events for normatization q_summing : bool If True, sum the counts in Q bins","title":"Parameters"},{"location":"api/background/#lr_reduction.background.side_background--returns","text":"numpy.ndarray Reflectivity background numpy.ndarray Reflectivity background error","title":"Returns"},{"location":"api/event_reduction/","text":"Event based reduction for the Liquids Reflectometer EventReflectivity Bases: object Data reduction for the Liquids Reflectometer. List of items to be taken care of outside this class: Edge points cropping Angle offset Putting runs together in one R(q) curve Scaling factors Pixel ranges include the min and max pixels. Parameters scattering_workspace Mantid workspace containing the reflected data direct_workspace Mantid workspace containing the direct beam data [if None, normalization won't be applied] signal_peak : list Pixel min and max for the specular peak signal_bck : list Pixel range of the background [if None, the background won't be subtracted] norm_peak : list Pixel range of the direct beam peak norm_bck : list Direct background subtraction is not used [deprecated] specular_pixel : float Pixel of the specular peak signal_low_res : list Pixel range of the specular peak out of the scattering plane norm_low_res : list Pixel range of the direct beam out of the scattering plane q_min : float Value of lowest q point q_step : float Step size in Q. Enter a negative value to get a log scale q_min : float Value of largest q point tof_range : list, None TOF range,or None theta : float Theta scattering angle in radians dead_time : float If not zero, dead time correction will be used paralyzable : bool If True, the dead time calculation will use the paralyzable approach dead_time_value : float value of the dead time in microsecond dead_time_tof_step : float TOF bin size in microsecond use_emmission_time : bool If True, the emission time delay will be computed __repr__ Generate a string representation of the reduction settings. Returns str String representation of the reduction settings bck_subtraction Perform background subtraction on the signal. This method provides a higher-level call for background subtraction, hiding the ranges needed to define the Region of Interest (ROI). Parameters normalize_to_single_pixel : bool If True, normalize the background to a single pixel. q_bins array of bins for the momentum transfer (q) values. wl_dist Array of wavelength (wl) values. wl_bins Array of bins for the wavelength (wl) values. q_summing : bool If True, sum the q values. Returns mantid.api.Workspace The workspace with the background subtracted. emission_time_correction Coorect TOF for emission time delay in the moderator. Parameters ws : mantid.api.Workspace Mantid workspace to extract correction meta-data from tofs : numpy.ndarray Array of uncorrected TOF values Returns numpy.ndarray Array of corrected TOF values extract_meta_data Extract meta data from the loaded data file. extract_meta_data_4A 4A-specific meta data extract_meta_data_4B 4B-specific meta data Distance from source to sample was 13.63 meters prior to the source to detector distance being determined with Bragg edges to be 15.75 m. gravity_correction Gravity correction for each event Parameters ws : mantid.api.Workspace Mantid workspace to extract correction meta-data from. wl_list : numpy.ndarray Array of wavelengths for each event. Returns numpy.ndarray Array of gravity-corrected theta values for each event, in radians. norm_bck_subtraction Higher-level call for background subtraction for the normalization run. off_specular Compute off-specular Parameters x_axis : int Axis selection from QX_VS_QZ, KZI_VS_KZF, DELTA_KZ_VS_QZ x_min : float Min value on x-axis x_max : float Max value on x-axis x_npts : int Number of points in x (negative will produce a log scale) z_min : float Min value on z-axis (if none, default Qz will be used) z_max : float Max value on z-axis (if none, default Qz will be used) z_npts : int Number of points in z (negative will produce a log scale) slice Retrieve a slice from the off-specular data. specular Compute specular reflectivity. For constant-Q binning, it's preferred to use tof_weighted=True. Parameters q_summing : bool Turns on constant-Q binning tof_weighted : bool If True, binning will be done by weighting each event to the DB distribution bck_in_q : bool If True, the background will be estimated in Q space using the constant-Q binning approach clean : bool If True, and Q summing is True, then leading artifact will be removed normalize : bool If True, and tof_weighted is False, normalization will be skipped Returns q_bins The Q bin boundaries refl The reflectivity values d_refl The uncertainties in the reflectivity values specular_unweighted Simple specular reflectivity calculation. This is the same approach as the original LR reduction, which sums up pixels without constant-Q binning. The original approach bins in TOF, then rebins the final results after transformation to Q. This approach bins directly to Q. Parameters q_summing : bool If True, sum the data in Q-space. normalize : bool If True, normalize the reflectivity by the direct beam. Returns q_bins The Q bin boundaries refl The reflectivity values d_refl The uncertainties in the reflectivity values specular_weighted Compute reflectivity by weighting each event by flux. This allows for summing in Q and to estimate the background in either Q or pixels next to the peak. Parameters q_summing : bool If True, sum the data in Q-space. bck_in_q : bool If True, subtract background along Q lines. Returns q_bins The Q bin boundaries refl The reflectivity values d_refl The uncertainties in the reflectivity values to_dict Returns meta-data to be used/stored. Returns dict Dictionary with meta-data apply_dead_time_correction Apply dead time correction, and ensure that it is done only once per workspace. Parameters ws Workspace with raw data to compute correction for template_data : reduction_template_reader.ReductionParameters Reduction parameters Returns mantid.api.Workspace Workspace with dead time correction applied compute_resolution Compute the Q resolution from the meta data. Parameters ws : mantid.api.Workspace Mantid workspace to extract correction meta-data from. theta : float Scattering angle in radians q_summing : bool If True, the pixel size will be used for the resolution Returns float The dQ/Q resolution (FWHM) get_attenuation_info Retrieve information about attenuation from a Mantid workspace. This function calculates the total thickness of all attenuators that are in the path of the beam by summing up the thicknesses of the attenuators specified in the global variable CD_ATTENUATORS . Parameters ws Mantid workspace from which to retrieve the attenuation information. Returns float The total thickness of the attenuators in the path of the beam. get_dead_time_correction Compute dead time correction to be applied to the reflectivity curve. The method will also try to load the error events from each of the data files to ensure that we properly estimate the dead time correction. Parameters ws Workspace with raw data to compute correction for template_data : reduction_template_reader.ReductionParameters Reduction parameters Returns mantid.api.Workspace Workspace with dead time correction to apply get_q_binning Determine Q binning. This function calculates the binning for Q values based on the provided minimum, maximum, and step values. If the step value is positive, it generates a linear binning. If the step value is negative, it generates a logarithmic binning. Parameters q_min : float The minimum Q value. q_max : float The maximum Q value. q_step : float The step size for Q binning. If positive, linear binning is used. If negative, logarithmic binning is used. Returns numpy.ndarray A numpy array of Q values based on the specified binning. get_wl_range Determine TOF range from the data Parameters ws Mantid workspace to work with Returns list [min, max] wavelength range process_attenuation Correct for absorption by assigning weight to each neutron event Parameters ws Mantid workspace to correct thickness: float Attenuator thickness in cm (default is 0). Returns Mantid workspace Corrected Mantid workspace read_settings Read settings file and return values for the given timestamp Parameters ws Mantid workspace Returns dict Dictionary with settings","title":"Event reduction"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity","text":"Bases: object Data reduction for the Liquids Reflectometer. List of items to be taken care of outside this class: Edge points cropping Angle offset Putting runs together in one R(q) curve Scaling factors Pixel ranges include the min and max pixels.","title":"EventReflectivity"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity--parameters","text":"scattering_workspace Mantid workspace containing the reflected data direct_workspace Mantid workspace containing the direct beam data [if None, normalization won't be applied] signal_peak : list Pixel min and max for the specular peak signal_bck : list Pixel range of the background [if None, the background won't be subtracted] norm_peak : list Pixel range of the direct beam peak norm_bck : list Direct background subtraction is not used [deprecated] specular_pixel : float Pixel of the specular peak signal_low_res : list Pixel range of the specular peak out of the scattering plane norm_low_res : list Pixel range of the direct beam out of the scattering plane q_min : float Value of lowest q point q_step : float Step size in Q. Enter a negative value to get a log scale q_min : float Value of largest q point tof_range : list, None TOF range,or None theta : float Theta scattering angle in radians dead_time : float If not zero, dead time correction will be used paralyzable : bool If True, the dead time calculation will use the paralyzable approach dead_time_value : float value of the dead time in microsecond dead_time_tof_step : float TOF bin size in microsecond use_emmission_time : bool If True, the emission time delay will be computed","title":"Parameters"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.__repr__","text":"Generate a string representation of the reduction settings.","title":"__repr__"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.__repr__--returns","text":"str String representation of the reduction settings","title":"Returns"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.bck_subtraction","text":"Perform background subtraction on the signal. This method provides a higher-level call for background subtraction, hiding the ranges needed to define the Region of Interest (ROI).","title":"bck_subtraction"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.bck_subtraction--parameters","text":"normalize_to_single_pixel : bool If True, normalize the background to a single pixel. q_bins array of bins for the momentum transfer (q) values. wl_dist Array of wavelength (wl) values. wl_bins Array of bins for the wavelength (wl) values. q_summing : bool If True, sum the q values.","title":"Parameters"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.bck_subtraction--returns","text":"mantid.api.Workspace The workspace with the background subtracted.","title":"Returns"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.emission_time_correction","text":"Coorect TOF for emission time delay in the moderator.","title":"emission_time_correction"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.emission_time_correction--parameters","text":"ws : mantid.api.Workspace Mantid workspace to extract correction meta-data from tofs : numpy.ndarray Array of uncorrected TOF values","title":"Parameters"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.emission_time_correction--returns","text":"numpy.ndarray Array of corrected TOF values","title":"Returns"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.extract_meta_data","text":"Extract meta data from the loaded data file.","title":"extract_meta_data"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.extract_meta_data_4A","text":"4A-specific meta data","title":"extract_meta_data_4A"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.extract_meta_data_4B","text":"4B-specific meta data Distance from source to sample was 13.63 meters prior to the source to detector distance being determined with Bragg edges to be 15.75 m.","title":"extract_meta_data_4B"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.gravity_correction","text":"Gravity correction for each event","title":"gravity_correction"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.gravity_correction--parameters","text":"ws : mantid.api.Workspace Mantid workspace to extract correction meta-data from. wl_list : numpy.ndarray Array of wavelengths for each event.","title":"Parameters"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.gravity_correction--returns","text":"numpy.ndarray Array of gravity-corrected theta values for each event, in radians.","title":"Returns"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.norm_bck_subtraction","text":"Higher-level call for background subtraction for the normalization run.","title":"norm_bck_subtraction"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.off_specular","text":"Compute off-specular","title":"off_specular"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.off_specular--parameters","text":"x_axis : int Axis selection from QX_VS_QZ, KZI_VS_KZF, DELTA_KZ_VS_QZ x_min : float Min value on x-axis x_max : float Max value on x-axis x_npts : int Number of points in x (negative will produce a log scale) z_min : float Min value on z-axis (if none, default Qz will be used) z_max : float Max value on z-axis (if none, default Qz will be used) z_npts : int Number of points in z (negative will produce a log scale)","title":"Parameters"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.slice","text":"Retrieve a slice from the off-specular data.","title":"slice"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.specular","text":"Compute specular reflectivity. For constant-Q binning, it's preferred to use tof_weighted=True.","title":"specular"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.specular--parameters","text":"q_summing : bool Turns on constant-Q binning tof_weighted : bool If True, binning will be done by weighting each event to the DB distribution bck_in_q : bool If True, the background will be estimated in Q space using the constant-Q binning approach clean : bool If True, and Q summing is True, then leading artifact will be removed normalize : bool If True, and tof_weighted is False, normalization will be skipped","title":"Parameters"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.specular--returns","text":"q_bins The Q bin boundaries refl The reflectivity values d_refl The uncertainties in the reflectivity values","title":"Returns"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.specular_unweighted","text":"Simple specular reflectivity calculation. This is the same approach as the original LR reduction, which sums up pixels without constant-Q binning. The original approach bins in TOF, then rebins the final results after transformation to Q. This approach bins directly to Q.","title":"specular_unweighted"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.specular_unweighted--parameters","text":"q_summing : bool If True, sum the data in Q-space. normalize : bool If True, normalize the reflectivity by the direct beam.","title":"Parameters"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.specular_unweighted--returns","text":"q_bins The Q bin boundaries refl The reflectivity values d_refl The uncertainties in the reflectivity values","title":"Returns"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.specular_weighted","text":"Compute reflectivity by weighting each event by flux. This allows for summing in Q and to estimate the background in either Q or pixels next to the peak.","title":"specular_weighted"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.specular_weighted--parameters","text":"q_summing : bool If True, sum the data in Q-space. bck_in_q : bool If True, subtract background along Q lines.","title":"Parameters"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.specular_weighted--returns","text":"q_bins The Q bin boundaries refl The reflectivity values d_refl The uncertainties in the reflectivity values","title":"Returns"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.to_dict","text":"Returns meta-data to be used/stored.","title":"to_dict"},{"location":"api/event_reduction/#lr_reduction.event_reduction.EventReflectivity.to_dict--returns","text":"dict Dictionary with meta-data","title":"Returns"},{"location":"api/event_reduction/#lr_reduction.event_reduction.apply_dead_time_correction","text":"Apply dead time correction, and ensure that it is done only once per workspace.","title":"apply_dead_time_correction"},{"location":"api/event_reduction/#lr_reduction.event_reduction.apply_dead_time_correction--parameters","text":"ws Workspace with raw data to compute correction for template_data : reduction_template_reader.ReductionParameters Reduction parameters","title":"Parameters"},{"location":"api/event_reduction/#lr_reduction.event_reduction.apply_dead_time_correction--returns","text":"mantid.api.Workspace Workspace with dead time correction applied","title":"Returns"},{"location":"api/event_reduction/#lr_reduction.event_reduction.compute_resolution","text":"Compute the Q resolution from the meta data.","title":"compute_resolution"},{"location":"api/event_reduction/#lr_reduction.event_reduction.compute_resolution--parameters","text":"ws : mantid.api.Workspace Mantid workspace to extract correction meta-data from. theta : float Scattering angle in radians q_summing : bool If True, the pixel size will be used for the resolution","title":"Parameters"},{"location":"api/event_reduction/#lr_reduction.event_reduction.compute_resolution--returns","text":"float The dQ/Q resolution (FWHM)","title":"Returns"},{"location":"api/event_reduction/#lr_reduction.event_reduction.get_attenuation_info","text":"Retrieve information about attenuation from a Mantid workspace. This function calculates the total thickness of all attenuators that are in the path of the beam by summing up the thicknesses of the attenuators specified in the global variable CD_ATTENUATORS .","title":"get_attenuation_info"},{"location":"api/event_reduction/#lr_reduction.event_reduction.get_attenuation_info--parameters","text":"ws Mantid workspace from which to retrieve the attenuation information.","title":"Parameters"},{"location":"api/event_reduction/#lr_reduction.event_reduction.get_attenuation_info--returns","text":"float The total thickness of the attenuators in the path of the beam.","title":"Returns"},{"location":"api/event_reduction/#lr_reduction.event_reduction.get_dead_time_correction","text":"Compute dead time correction to be applied to the reflectivity curve. The method will also try to load the error events from each of the data files to ensure that we properly estimate the dead time correction.","title":"get_dead_time_correction"},{"location":"api/event_reduction/#lr_reduction.event_reduction.get_dead_time_correction--parameters","text":"ws Workspace with raw data to compute correction for template_data : reduction_template_reader.ReductionParameters Reduction parameters","title":"Parameters"},{"location":"api/event_reduction/#lr_reduction.event_reduction.get_dead_time_correction--returns","text":"mantid.api.Workspace Workspace with dead time correction to apply","title":"Returns"},{"location":"api/event_reduction/#lr_reduction.event_reduction.get_q_binning","text":"Determine Q binning. This function calculates the binning for Q values based on the provided minimum, maximum, and step values. If the step value is positive, it generates a linear binning. If the step value is negative, it generates a logarithmic binning.","title":"get_q_binning"},{"location":"api/event_reduction/#lr_reduction.event_reduction.get_q_binning--parameters","text":"q_min : float The minimum Q value. q_max : float The maximum Q value. q_step : float The step size for Q binning. If positive, linear binning is used. If negative, logarithmic binning is used.","title":"Parameters"},{"location":"api/event_reduction/#lr_reduction.event_reduction.get_q_binning--returns","text":"numpy.ndarray A numpy array of Q values based on the specified binning.","title":"Returns"},{"location":"api/event_reduction/#lr_reduction.event_reduction.get_wl_range","text":"Determine TOF range from the data","title":"get_wl_range"},{"location":"api/event_reduction/#lr_reduction.event_reduction.get_wl_range--parameters","text":"ws Mantid workspace to work with","title":"Parameters"},{"location":"api/event_reduction/#lr_reduction.event_reduction.get_wl_range--returns","text":"list [min, max] wavelength range","title":"Returns"},{"location":"api/event_reduction/#lr_reduction.event_reduction.process_attenuation","text":"Correct for absorption by assigning weight to each neutron event","title":"process_attenuation"},{"location":"api/event_reduction/#lr_reduction.event_reduction.process_attenuation--parameters","text":"ws Mantid workspace to correct thickness: float Attenuator thickness in cm (default is 0).","title":"Parameters"},{"location":"api/event_reduction/#lr_reduction.event_reduction.process_attenuation--returns","text":"Mantid workspace Corrected Mantid workspace","title":"Returns"},{"location":"api/event_reduction/#lr_reduction.event_reduction.read_settings","text":"Read settings file and return values for the given timestamp","title":"read_settings"},{"location":"api/event_reduction/#lr_reduction.event_reduction.read_settings--parameters","text":"ws Mantid workspace","title":"Parameters"},{"location":"api/event_reduction/#lr_reduction.event_reduction.read_settings--returns","text":"dict Dictionary with settings","title":"Returns"},{"location":"api/output/","text":"Write R(q) output RunCollection A collection of runs to assemble into a single R(Q) add Add a partial R(q) to the collection add_from_file Read a partial result file and add it to the collection merge Merge the collection of runs save_ascii Save R(Q) in ascii format read_file Read a data file and extract meta data","title":"Output"},{"location":"api/output/#lr_reduction.output.RunCollection","text":"A collection of runs to assemble into a single R(Q)","title":"RunCollection"},{"location":"api/output/#lr_reduction.output.RunCollection.add","text":"Add a partial R(q) to the collection","title":"add"},{"location":"api/output/#lr_reduction.output.RunCollection.add_from_file","text":"Read a partial result file and add it to the collection","title":"add_from_file"},{"location":"api/output/#lr_reduction.output.RunCollection.merge","text":"Merge the collection of runs","title":"merge"},{"location":"api/output/#lr_reduction.output.RunCollection.save_ascii","text":"Save R(Q) in ascii format","title":"save_ascii"},{"location":"api/output/#lr_reduction.output.read_file","text":"Read a data file and extract meta data","title":"read_file"},{"location":"api/peak_finding/","text":"fit_signal_flat_bck Fit a Gaussian peak. :param x: list of x values :param y: list of y values :param x_min: start index of the list of points :param x_max: end index of the list of points :param center: estimated center position :param sigma: if provided, the sigma will be fixed to the given value :param background: if provided, the value will be subtracted from y process_data Process a Mantid workspace to extract counts vs pixel. :param workspace: Mantid workspace :param summed: if True, the x pixels with be summed :param tof_step: TOF bin size","title":"Peak finding"},{"location":"api/peak_finding/#lr_reduction.peak_finding.fit_signal_flat_bck","text":"Fit a Gaussian peak. :param x: list of x values :param y: list of y values :param x_min: start index of the list of points :param x_max: end index of the list of points :param center: estimated center position :param sigma: if provided, the sigma will be fixed to the given value :param background: if provided, the value will be subtracted from y","title":"fit_signal_flat_bck"},{"location":"api/peak_finding/#lr_reduction.peak_finding.process_data","text":"Process a Mantid workspace to extract counts vs pixel. :param workspace: Mantid workspace :param summed: if True, the x pixels with be summed :param tof_step: TOF bin size","title":"process_data"},{"location":"api/reduction_template_reader/","text":"RefRed template reader. Adapted from Mantid code. ReductionParameters Bases: object from_dict Update object's attributes with a dictionary with entries of the type attribute_name: attribute_value. Parameters permissible: bool allow keys in data_dict that are not attribute names of ReductionParameters instances. Reading from data_dict will result in this instance having new attributes not defined in __init__() Raises ValueError when permissible=False and one entry (or more) of the dictionary is not an attribute of this object from_xml_element Read in data from XML @param xml_str: text to read the data from to_xml Create XML from the current data. from_xml Read in data from XML string getText Utility method to extract text out of an XML node to_xml Create XML from the current data.","title":"Reduction template reader"},{"location":"api/reduction_template_reader/#lr_reduction.reduction_template_reader.ReductionParameters","text":"Bases: object","title":"ReductionParameters"},{"location":"api/reduction_template_reader/#lr_reduction.reduction_template_reader.ReductionParameters.from_dict","text":"Update object's attributes with a dictionary with entries of the type attribute_name: attribute_value.","title":"from_dict"},{"location":"api/reduction_template_reader/#lr_reduction.reduction_template_reader.ReductionParameters.from_dict--parameters","text":"permissible: bool allow keys in data_dict that are not attribute names of ReductionParameters instances. Reading from data_dict will result in this instance having new attributes not defined in __init__()","title":"Parameters"},{"location":"api/reduction_template_reader/#lr_reduction.reduction_template_reader.ReductionParameters.from_dict--raises","text":"ValueError when permissible=False and one entry (or more) of the dictionary is not an attribute of this object","title":"Raises"},{"location":"api/reduction_template_reader/#lr_reduction.reduction_template_reader.ReductionParameters.from_xml_element","text":"Read in data from XML @param xml_str: text to read the data from","title":"from_xml_element"},{"location":"api/reduction_template_reader/#lr_reduction.reduction_template_reader.ReductionParameters.to_xml","text":"Create XML from the current data.","title":"to_xml"},{"location":"api/reduction_template_reader/#lr_reduction.reduction_template_reader.from_xml","text":"Read in data from XML string","title":"from_xml"},{"location":"api/reduction_template_reader/#lr_reduction.reduction_template_reader.getText","text":"Utility method to extract text out of an XML node","title":"getText"},{"location":"api/reduction_template_reader/#lr_reduction.reduction_template_reader.to_xml","text":"Create XML from the current data.","title":"to_xml"},{"location":"api/template/","text":"Reduce a data run using a template generated by RefRed process_from_template The clean option removes leading zeros and the drop when doing q-summing read_template Read template from file. @param sequence_number: the ID of the data set within the sequence of runs scaling_factor Apply scaling factor from reference scaling data @param workspace: Mantid workspace","title":"Template"},{"location":"api/template/#lr_reduction.template.process_from_template","text":"The clean option removes leading zeros and the drop when doing q-summing","title":"process_from_template"},{"location":"api/template/#lr_reduction.template.read_template","text":"Read template from file. @param sequence_number: the ID of the data set within the sequence of runs","title":"read_template"},{"location":"api/template/#lr_reduction.template.scaling_factor","text":"Apply scaling factor from reference scaling data @param workspace: Mantid workspace","title":"scaling_factor"},{"location":"api/time_resolved/","text":"Time-resolved data reduction reduce_30Hz_from_ws Perform 30Hz reduction @param meas_ws_30Hz: Mantid workspace of the data we want to reduce @param ref_ws_30Hz: Mantid workspace of the reference data, take with the same config @param data_60Hz: reduced reference data at 60Hz @param template_data: template data object (for 30Hz) @param scan_index: scan index to use within the template. reduce_30Hz_slices_ws Perform 30Hz reduction @param meas_ws_30Hz: workspace of the data we want to reduce @param ref_ws_30Hz: workspace of the reference data, take with the same config @param ref_data_60Hz: file path of the reduce data file at 60Hz @param template_30Hz: file path of the template file for 30Hz @param time_interval: time step in seconds @param scan_index: scan index to use within the template. reduce_slices_ws Perform time-resolved reduction :param meas_ws: workspace of the data we want to reduce :param template_file: autoreduction template file :param time_interval: time step in seconds :param scan_index: scan index to use within the template. :param theta_value: force theta value :param theta_offset: add a theta offset, defaults to zero","title":"Time resolved"},{"location":"api/time_resolved/#lr_reduction.time_resolved.reduce_30Hz_from_ws","text":"Perform 30Hz reduction @param meas_ws_30Hz: Mantid workspace of the data we want to reduce @param ref_ws_30Hz: Mantid workspace of the reference data, take with the same config @param data_60Hz: reduced reference data at 60Hz @param template_data: template data object (for 30Hz) @param scan_index: scan index to use within the template.","title":"reduce_30Hz_from_ws"},{"location":"api/time_resolved/#lr_reduction.time_resolved.reduce_30Hz_slices_ws","text":"Perform 30Hz reduction @param meas_ws_30Hz: workspace of the data we want to reduce @param ref_ws_30Hz: workspace of the reference data, take with the same config @param ref_data_60Hz: file path of the reduce data file at 60Hz @param template_30Hz: file path of the template file for 30Hz @param time_interval: time step in seconds @param scan_index: scan index to use within the template.","title":"reduce_30Hz_slices_ws"},{"location":"api/time_resolved/#lr_reduction.time_resolved.reduce_slices_ws","text":"Perform time-resolved reduction :param meas_ws: workspace of the data we want to reduce :param template_file: autoreduction template file :param time_interval: time step in seconds :param scan_index: scan index to use within the template. :param theta_value: force theta value :param theta_offset: add a theta offset, defaults to zero","title":"reduce_slices_ws"},{"location":"api/utils/","text":"amend_config Context manager to safely modify Mantid Configuration Service while the function is executed. Parameters new_config (key, value) pairs to substitute in the configuration service data_dir prepend one (when passing a string) or more (when passing a list) directories to the list of data search directories. Alternatively, replace instead of prepend. data_dir_insert_mode How to insert the data directories. Options are: \"prepend\" (default) and \"replace\".","title":"Utils"},{"location":"api/utils/#lr_reduction.utils.amend_config","text":"Context manager to safely modify Mantid Configuration Service while the function is executed.","title":"amend_config"},{"location":"api/utils/#lr_reduction.utils.amend_config--parameters","text":"new_config (key, value) pairs to substitute in the configuration service data_dir prepend one (when passing a string) or more (when passing a list) directories to the list of data search directories. Alternatively, replace instead of prepend. data_dir_insert_mode How to insert the data directories. Options are: \"prepend\" (default) and \"replace\".","title":"Parameters"},{"location":"api/workflow/","text":"Autoreduction process for the Liquids Reflectometer assemble_results Find related runs and assemble them in one R(q) data set Parameters first_run : int The first run number in the sequence output_dir : str Directory where the output files are saved average_overlap : bool If True, the overlapping points will be averaged is_live : bool If True, the data is live and will be saved in a separate file to avoid conflict with auto-reduction Returns seq_list : list The sequence identifiers run_list : list The run numbers offset_from_first_run Find a theta offset by comparing the peak location of the reflected and direct beam compared to the theta value in the meta data. When processing the first run of a set, store that offset in a file so it can be used for later runs. Parameters ws : Mantid workspace The workspace to process template_file : str Path to the template file output_dir : str Directory where the output files are saved Returns float The theta offset reduce Function called by reduce_REFL.py, which lives in /SNS/REF_L/shared/autoreduce and is called by the automated reduction workflow. If average_overlap is used, overlapping points will be averaged, otherwise they will be left in the final data file. Parameters average_overlap : bool If True, the overlapping points will be averaged q_summing : bool If True, constant-Q binning will be used bck_in_q : bool If True, and constant-Q binning is used, the background will be estimated along constant-Q lines rather than along TOF/pixel boundaries. theta_offset : float Theta offset to apply. If None, the template value will be used. is_live : bool If True, the data is live and will be saved in a separate file to avoid conflict with auto-reduction output_dir : str Directory where the output files will be saved template_file : str Path to the template file containing the reduction parameters Returns int The sequence identifier for the run sequence reduce_explorer Very simple rough reduction for when playing around. Parameters ws : Mantid workspace The workspace to process ws_db : Mantid workspace The workspace with the direct beam data theta_pv : str The PV name for the theta value center_pixel : int The pixel number for the center of the reflected beam db_center_pixel : int The pixel number for the center of the direct beam peak_width : int The width of the peak to use for the reflected beam Returns qz_mid : numpy.ndarray The Q values refl : numpy.ndarray The reflectivity values d_refl : numpy.ndarray The uncertainty in the reflectivity write_template Read the appropriate entry in a template file and save an updated copy with the updated run number. Parameters seq_list : list The sequence identifiers run_list : list The run numbers template_file : str Path to the template file output_dir : str Directory where the output files are saved","title":"Workflow"},{"location":"api/workflow/#lr_reduction.workflow.assemble_results","text":"Find related runs and assemble them in one R(q) data set","title":"assemble_results"},{"location":"api/workflow/#lr_reduction.workflow.assemble_results--parameters","text":"first_run : int The first run number in the sequence output_dir : str Directory where the output files are saved average_overlap : bool If True, the overlapping points will be averaged is_live : bool If True, the data is live and will be saved in a separate file to avoid conflict with auto-reduction","title":"Parameters"},{"location":"api/workflow/#lr_reduction.workflow.assemble_results--returns","text":"seq_list : list The sequence identifiers run_list : list The run numbers","title":"Returns"},{"location":"api/workflow/#lr_reduction.workflow.offset_from_first_run","text":"Find a theta offset by comparing the peak location of the reflected and direct beam compared to the theta value in the meta data. When processing the first run of a set, store that offset in a file so it can be used for later runs.","title":"offset_from_first_run"},{"location":"api/workflow/#lr_reduction.workflow.offset_from_first_run--parameters","text":"ws : Mantid workspace The workspace to process template_file : str Path to the template file output_dir : str Directory where the output files are saved","title":"Parameters"},{"location":"api/workflow/#lr_reduction.workflow.offset_from_first_run--returns","text":"float The theta offset","title":"Returns"},{"location":"api/workflow/#lr_reduction.workflow.reduce","text":"Function called by reduce_REFL.py, which lives in /SNS/REF_L/shared/autoreduce and is called by the automated reduction workflow. If average_overlap is used, overlapping points will be averaged, otherwise they will be left in the final data file.","title":"reduce"},{"location":"api/workflow/#lr_reduction.workflow.reduce--parameters","text":"average_overlap : bool If True, the overlapping points will be averaged q_summing : bool If True, constant-Q binning will be used bck_in_q : bool If True, and constant-Q binning is used, the background will be estimated along constant-Q lines rather than along TOF/pixel boundaries. theta_offset : float Theta offset to apply. If None, the template value will be used. is_live : bool If True, the data is live and will be saved in a separate file to avoid conflict with auto-reduction output_dir : str Directory where the output files will be saved template_file : str Path to the template file containing the reduction parameters","title":"Parameters"},{"location":"api/workflow/#lr_reduction.workflow.reduce--returns","text":"int The sequence identifier for the run sequence","title":"Returns"},{"location":"api/workflow/#lr_reduction.workflow.reduce_explorer","text":"Very simple rough reduction for when playing around.","title":"reduce_explorer"},{"location":"api/workflow/#lr_reduction.workflow.reduce_explorer--parameters","text":"ws : Mantid workspace The workspace to process ws_db : Mantid workspace The workspace with the direct beam data theta_pv : str The PV name for the theta value center_pixel : int The pixel number for the center of the reflected beam db_center_pixel : int The pixel number for the center of the direct beam peak_width : int The width of the peak to use for the reflected beam","title":"Parameters"},{"location":"api/workflow/#lr_reduction.workflow.reduce_explorer--returns","text":"qz_mid : numpy.ndarray The Q values refl : numpy.ndarray The reflectivity values d_refl : numpy.ndarray The uncertainty in the reflectivity","title":"Returns"},{"location":"api/workflow/#lr_reduction.workflow.write_template","text":"Read the appropriate entry in a template file and save an updated copy with the updated run number.","title":"write_template"},{"location":"api/workflow/#lr_reduction.workflow.write_template--parameters","text":"seq_list : list The sequence identifiers run_list : list The run numbers template_file : str Path to the template file output_dir : str Directory where the output files are saved","title":"Parameters"},{"location":"developer/contributing/","text":"Contributing Guide Contributions to this project are welcome. All contributors agree to the following: It is assumed that the contributor is an ORNL employee and belongs to the development team. Thus the following instructions are specific to ORNL development team's process. You have permission and any required rights to submit your contribution. Your contribution is provided under the license of this project and may be redistributed as such. All contributions to this project are public. All contributions must be \"signed off\" in the commit log and by doing so you agree to the above. Getting access to the main project Direct commit access to the project is currently restricted to core developers. All other contributions should be done through pull requests.","title":"Contributing Guide"},{"location":"developer/contributing/#contributing-guide","text":"Contributions to this project are welcome. All contributors agree to the following: It is assumed that the contributor is an ORNL employee and belongs to the development team. Thus the following instructions are specific to ORNL development team's process. You have permission and any required rights to submit your contribution. Your contribution is provided under the license of this project and may be redistributed as such. All contributions to this project are public. All contributions must be \"signed off\" in the commit log and by doing so you agree to the above.","title":"Contributing Guide"},{"location":"developer/contributing/#getting-access-to-the-main-project","text":"Direct commit access to the project is currently restricted to core developers. All other contributions should be done through pull requests.","title":"Getting access to the main project"},{"location":"developer/developer/","text":"Developer Documentation Local Environment pre-commit Hooks Development procedure Updating mantid dependency Using the Data Repository Coverage reports Building the documentation Creating a stable release Local Environment For purposes of development, create conda environment lr_reduction with file environment.yml , and then install the package in development mode with pip : $ cd /path/to/lr_reduction/ $ conda create env --solver libmamba --file ./environment.yml $ conda activate lr_reduction (lr_reduction)$ pip install -e ./ By installing the package in development mode, one doesn't need to re-install package lr_reduction in conda environment lr_reduction after every change to the source code. pre-commit Hooks Activate the hooks by typing in the terminal: $ cd /path/to/mr_reduction/ $ conda activate mr_reduction (mr_reduction)$ pre-commit install Development procedure A developer is assigned with a task during neutron status meeting and changes the task's status to In Progress . The developer creates a branch off next and completes the task in this branch. The developer creates a pull request (PR) off next . Any new features or bugfixes must be covered by new and/or refactored automated tests. The developer asks for another developer as a reviewer to review the PR. A PR can only be approved and merged by the reviewer. The developer changes the task\u2019s status to Complete and closes the associated issue. Updating mantid dependency The mantid version and the mantid conda channel ( mantid/label/main or mantid/label/nightly ) must be synchronized across these files: environment.yml conda.recipe/meta.yml .github/workflows/package.yml Using the Data Repository To run the integration tests in your local environment, it is necessary first to download the data files. Because of their size, the files are stored in the Git LFS repository lr_reduction-data <https://code.ornl.gov/sns-hfir-scse/infrastructure/test-data/liquidsreflectometer-data> _. It is necessary to have package git-lfs installed in your machine. $ sudo apt install git-lfs After this step, initialize or update the data repository: $ cd /path/to/lr_reduction $ git submodule update --init This will either clone liquidsreflectometer-data into /path/to/lr_reduction/tests/liquidsreflectometer-data or bring the liquidsreflectometer-data 's refspec in sync with the refspec listed within file /path/to/liquidsreflectometer/.gitmodules . An intro to Git LFS in the context of the Neutron Data Project is found in the Confluence pages <https://ornl-neutrons.atlassian.net/wiki/spaces/NDPD/pages/19103745/Using+git-lfs+for+test+data> _ (login required). Coverage reports GitHuh actions create reports for unit and integration tests, then combine into one report and upload it to Codecov <https://app.codecov.io/gh/neutrons/lr_reduction> _. Building the documentation A repository webhook is setup to automatically trigger the latest documentation build by GitHub actions. To manually build the documentation: $ conda activate lr_reduction (lr_reduction)$ make docs After this, point your browser to file:///path/to/lr_reduction/docs/build/html/index.html Creating a stable release patch release, it may be allowed to bypass the creation of a candidate release. Still, we must update branch qa first, then create the release tag in branch main . For instance, to create patch version \"v2.1.1\": VERSION=\"v2.1.2\" # update the local repository git fetch --all --prune git fetch --prune --prune-tags origin # update branch qa from next, possibly bringing work done in qa missing in next git switch next git rebase -v origin/next git merge --no-edit origin/qa # commit message is automatically generated git push origin next # required to \"link\" qa to next, for future fast-forward git switch qa git rebase -v origin/qa git merge --ff-only origin/next # update branch main from qa git merge --no-edit origin/main # commit message is automatically generated git push origin qa # required to \"link\" main to qa, for future fast-forward git switch main git rebase -v origin/main git merge --ff-only origin/qa git tag $VERSION git push origin --tags main minor or major release, we create a stable release after we have created a Candidate release. For this customary procedure, follow: The Software Maturity Model for continous versioning as well as creating release candidates and stable releases. Update the :ref: Release Notes <release_notes> with major fixes, updates and additions since last stable release.","title":"Developer Documentation"},{"location":"developer/developer/#developer-documentation","text":"Local Environment pre-commit Hooks Development procedure Updating mantid dependency Using the Data Repository Coverage reports Building the documentation Creating a stable release","title":"Developer Documentation"},{"location":"developer/developer/#local-environment","text":"For purposes of development, create conda environment lr_reduction with file environment.yml , and then install the package in development mode with pip : $ cd /path/to/lr_reduction/ $ conda create env --solver libmamba --file ./environment.yml $ conda activate lr_reduction (lr_reduction)$ pip install -e ./ By installing the package in development mode, one doesn't need to re-install package lr_reduction in conda environment lr_reduction after every change to the source code.","title":"Local Environment"},{"location":"developer/developer/#pre-commit-hooks","text":"Activate the hooks by typing in the terminal: $ cd /path/to/mr_reduction/ $ conda activate mr_reduction (mr_reduction)$ pre-commit install","title":"pre-commit Hooks"},{"location":"developer/developer/#development-procedure","text":"A developer is assigned with a task during neutron status meeting and changes the task's status to In Progress . The developer creates a branch off next and completes the task in this branch. The developer creates a pull request (PR) off next . Any new features or bugfixes must be covered by new and/or refactored automated tests. The developer asks for another developer as a reviewer to review the PR. A PR can only be approved and merged by the reviewer. The developer changes the task\u2019s status to Complete and closes the associated issue.","title":"Development procedure"},{"location":"developer/developer/#updating-mantid-dependency","text":"The mantid version and the mantid conda channel ( mantid/label/main or mantid/label/nightly ) must be synchronized across these files: environment.yml conda.recipe/meta.yml .github/workflows/package.yml","title":"Updating mantid dependency"},{"location":"developer/developer/#using-the-data-repository","text":"To run the integration tests in your local environment, it is necessary first to download the data files. Because of their size, the files are stored in the Git LFS repository lr_reduction-data <https://code.ornl.gov/sns-hfir-scse/infrastructure/test-data/liquidsreflectometer-data> _. It is necessary to have package git-lfs installed in your machine. $ sudo apt install git-lfs After this step, initialize or update the data repository: $ cd /path/to/lr_reduction $ git submodule update --init This will either clone liquidsreflectometer-data into /path/to/lr_reduction/tests/liquidsreflectometer-data or bring the liquidsreflectometer-data 's refspec in sync with the refspec listed within file /path/to/liquidsreflectometer/.gitmodules . An intro to Git LFS in the context of the Neutron Data Project is found in the Confluence pages <https://ornl-neutrons.atlassian.net/wiki/spaces/NDPD/pages/19103745/Using+git-lfs+for+test+data> _ (login required).","title":"Using the Data Repository"},{"location":"developer/developer/#coverage-reports","text":"GitHuh actions create reports for unit and integration tests, then combine into one report and upload it to Codecov <https://app.codecov.io/gh/neutrons/lr_reduction> _.","title":"Coverage reports"},{"location":"developer/developer/#building-the-documentation","text":"A repository webhook is setup to automatically trigger the latest documentation build by GitHub actions. To manually build the documentation: $ conda activate lr_reduction (lr_reduction)$ make docs After this, point your browser to file:///path/to/lr_reduction/docs/build/html/index.html","title":"Building the documentation"},{"location":"developer/developer/#creating-a-stable-release","text":"patch release, it may be allowed to bypass the creation of a candidate release. Still, we must update branch qa first, then create the release tag in branch main . For instance, to create patch version \"v2.1.1\": VERSION=\"v2.1.2\" # update the local repository git fetch --all --prune git fetch --prune --prune-tags origin # update branch qa from next, possibly bringing work done in qa missing in next git switch next git rebase -v origin/next git merge --no-edit origin/qa # commit message is automatically generated git push origin next # required to \"link\" qa to next, for future fast-forward git switch qa git rebase -v origin/qa git merge --ff-only origin/next # update branch main from qa git merge --no-edit origin/main # commit message is automatically generated git push origin qa # required to \"link\" main to qa, for future fast-forward git switch main git rebase -v origin/main git merge --ff-only origin/qa git tag $VERSION git push origin --tags main minor or major release, we create a stable release after we have created a Candidate release. For this customary procedure, follow: The Software Maturity Model for continous versioning as well as creating release candidates and stable releases. Update the :ref: Release Notes <release_notes> with major fixes, updates and additions since last stable release.","title":"Creating a stable release"},{"location":"user/conda_environments/","text":"Conda Environments Three conda environments are available in the analysis nodes, beamline machines, as well as the jupyter notebook severs. On a terminal: $ conda activate <environment> where <environment> is one of lr_reduction , lr_reduction-qa , and lr_reduction-dev lr_reduction Environment Activates the latest stable release of lr_reduction . Typically users will reduce their data in this environment. lr_reduction-qa Environment Activates a release-candidate environment. Instrument scientists and computational instrument scientists will carry out testing on this environment to prevent bugs being introduce in the next stable release. lr_reduction-dev Environment Activates the environment corresponding to the latest changes in the source code. Instrument scientists and computational instrument scientists will test the latest changes to lr_reduction in this environment.","title":"Conda Environments"},{"location":"user/conda_environments/#conda-environments","text":"Three conda environments are available in the analysis nodes, beamline machines, as well as the jupyter notebook severs. On a terminal: $ conda activate <environment> where <environment> is one of lr_reduction , lr_reduction-qa , and lr_reduction-dev","title":"Conda Environments"},{"location":"user/conda_environments/#lr_reduction-environment","text":"Activates the latest stable release of lr_reduction . Typically users will reduce their data in this environment.","title":"lr_reduction Environment"},{"location":"user/conda_environments/#lr_reduction-qa-environment","text":"Activates a release-candidate environment. Instrument scientists and computational instrument scientists will carry out testing on this environment to prevent bugs being introduce in the next stable release.","title":"lr_reduction-qa Environment"},{"location":"user/conda_environments/#lr_reduction-dev-environment","text":"Activates the environment corresponding to the latest changes in the source code. Instrument scientists and computational instrument scientists will test the latest changes to lr_reduction in this environment.","title":"lr_reduction-dev Environment"}]}